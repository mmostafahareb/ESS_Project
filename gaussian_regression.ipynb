{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8L6ANjg9SzyvaJ5uJKXlz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmostafahareb/ESS_Project/blob/main/gaussian_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg2Mv3Yev7FO",
        "outputId": "9daecb3c-2877-4345-ef4c-b77885153103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'alpha': 0.1, 'kernel__length_scale': 0.01}\n",
            "Best score:  0.00014711829093236537\n",
            "Mean squared error on test set:  0.00016082866805543846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('soh_lithium_ion.csv')\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop('SOH_discharge_capacity', axis=1)\n",
        "y = df['SOH_discharge_capacity']\n",
        "\n",
        "# Define the K-fold cross-validation object\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define the model to use for the GridSearchCV\n",
        "kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-1, 100000.0))\n",
        "model = GaussianProcessRegressor(kernel=kernel, alpha=0.1, n_restarts_optimizer=10, random_state=42)\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "param_grid = {'kernel__length_scale': np.logspace(-2, 2, 5),\n",
        "              'alpha': [0.1, 1, 10]}\n",
        "\n",
        "# Define the GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters and the best score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", -grid_search.best_score_)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the best model to the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the mean squared error of the best model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean squared error on test set: \", mse)\n"
      ]
    }
  ]
}